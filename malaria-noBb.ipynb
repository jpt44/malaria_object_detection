{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-label Prediction\n",
    "This notebooks does multi-label prediction on malaria dataset. It doesn't calculate bounding boxes (BB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['red blood cell' 'leukocyte' 'schizont' 'gametocyte' 'ring' 'trophozoite']\n"
     ]
    }
   ],
   "source": [
    "types = {\"schizont\": 2, \"gametocyte\": 3, \"ring\": 4, \"trophozoite\": 5, \"red blood cell\": 0, \"leukocyte\": 1}\n",
    "\n",
    "typeArr = np.empty(shape=(6,),dtype=\"U32\")\n",
    "\n",
    "for k in types:\n",
    "    typeArr[types[k],] = k\n",
    "    \n",
    "print(typeArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "818 390\n"
     ]
    }
   ],
   "source": [
    "trainingImages = tf.data.Dataset.list_files(\"malaria/training/*.png\", shuffle=False)\n",
    "testImages = tf.data.Dataset.list_files(\"malaria/test/*.png\", shuffle=False)\n",
    "\n",
    "print(len(trainingImages), len(testImages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Ingestion Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE= 32\n",
    "img_shape = (224,224,3) # height, width, channels\n",
    "autoTune = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_npy_file(item):\n",
    "    data = np.load(item.numpy().decode('UTF-8'), allow_pickle=True, fix_imports=False)\n",
    "    return data.astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_img(img: str, img_height: int, img_width: int):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    png = tf.io.decode_png(img, channels=3, dtype=tf.dtypes.uint8)\n",
    "    \n",
    "    # resize the image to the desired size\n",
    "    return tf.image.resize(png, [img_height, img_width], method=\"bilinear\", preserve_aspect_ratio=False, antialias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(file_path):\n",
    "    \n",
    "    imgName = tf.strings.regex_replace(file_path, \"training|test\", \"Y_nobb\", replace_global=False)\n",
    "    imgName = tf.strings.regex_replace(imgName, \".png\", \".npy\", replace_global=False)\n",
    "    \n",
    "    label = tf.py_function(read_npy_file, [imgName], [tf.float32])\n",
    "    label = tf.reshape(label, [6,])\n",
    "        \n",
    "  # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img, img_shape[0], img_shape[1])\n",
    "    \n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_for_performance(ds, shuffle=True):\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=1000)\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "    ds = ds.prefetch(buffer_size=autoTune)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\n",
    "train_ds = trainingImages.map(process_path, num_parallel_calls=autoTune)\n",
    "test_ds = testImages.map(process_path, num_parallel_calls=autoTune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape:  (224, 224, 3)\n",
      "Label:  [1. 0. 0. 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "for image, label in train_ds.take(1):\n",
    "    print(\"Image shape: \", image.numpy().shape)\n",
    "    print(\"Label: \", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = configure_for_performance(train_ds)\n",
    "test_ds = configure_for_performance(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "print(\"Num GPUs Available: \", num_gpus)\n",
    "\n",
    "if num_gpus>0:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "else:\n",
    "    strategy = tf.distribute.OneDeviceStrategy(device = \"/device:CPU:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model parameters\n",
    "EPOCHS = 50\n",
    "\n",
    "num_classes = 6\n",
    "lr = 1e-3\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_bin_acc', min_delta=1e-4, patience=10, verbose=0, restore_best_weights=True)\n",
    "terminate = tf.keras.callbacks.TerminateOnNaN()\n",
    "\n",
    "myCallbacks = [early_stop, terminate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(lr, num_classes, img_shape):\n",
    "    \n",
    "    inputLayer = tf.keras.Input(shape=img_shape)\n",
    "    \n",
    "    res = tf.keras.applications.InceptionV3(include_top=False,weights=\"imagenet\",\n",
    "    input_shape=img_shape,\n",
    "    pooling=None, classifier_activation=None)\n",
    "    \n",
    "    x = res(inputLayer)\n",
    "    x = tf.keras.layers.GlobalMaxPooling2D(data_format=\"channels_last\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(32, \"relu\", use_bias=True, kernel_initializer='glorot_normal')(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Dense(16, \"relu\", use_bias=True, kernel_initializer='glorot_normal')(x)\n",
    "    x = tf.keras.layers.Dense(num_classes, \"sigmoid\", use_bias=True, kernel_initializer='glorot_normal')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputLayer], outputs=[x])\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    met = tf.keras.metrics.BinaryAccuracy(name='bin_acc', dtype=None, threshold=0.5)\n",
    "    model.compile(opt, loss=\"binary_crossentropy\", metrics=[met])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "inception_v3 (Functional)    (None, 5, 5, 2048)        21802784  \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                65568     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 102       \n",
      "=================================================================\n",
      "Total params: 21,868,982\n",
      "Trainable params: 21,834,550\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = createModel(lr, num_classes, img_shape)\n",
    "    model.summary()\n",
    "    model.fit(train_ds, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1, validation_data=test_ds, callbacks = myCallbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "26/26 [==============================] - 33s 671ms/step - loss: 0.6805 - bin_acc: 0.7148 - val_loss: 101.3192 - val_bin_acc: 0.7299\n",
      "Epoch 2/50\n",
      "26/26 [==============================] - 22s 561ms/step - loss: 0.4342 - bin_acc: 0.8323 - val_loss: 4.1241 - val_bin_acc: 0.6534\n",
      "Epoch 3/50\n",
      "26/26 [==============================] - 24s 608ms/step - loss: 0.3819 - bin_acc: 0.8510 - val_loss: 3.1325 - val_bin_acc: 0.8299\n",
      "Epoch 4/50\n",
      "26/26 [==============================] - 24s 624ms/step - loss: 0.3616 - bin_acc: 0.8566 - val_loss: 0.8411 - val_bin_acc: 0.8308\n",
      "Epoch 5/50\n",
      "26/26 [==============================] - 22s 559ms/step - loss: 0.3356 - bin_acc: 0.8717 - val_loss: 4.3309 - val_bin_acc: 0.7333\n",
      "Epoch 6/50\n",
      "26/26 [==============================] - 22s 551ms/step - loss: 0.3225 - bin_acc: 0.8755 - val_loss: 0.4746 - val_bin_acc: 0.8415\n",
      "Epoch 7/50\n",
      "26/26 [==============================] - 22s 543ms/step - loss: 0.3250 - bin_acc: 0.8704 - val_loss: 1.2489 - val_bin_acc: 0.8380\n",
      "Epoch 8/50\n",
      "26/26 [==============================] - 23s 580ms/step - loss: 0.3208 - bin_acc: 0.8727 - val_loss: 0.3901 - val_bin_acc: 0.8436\n",
      "Epoch 9/50\n",
      "26/26 [==============================] - 24s 620ms/step - loss: 0.2844 - bin_acc: 0.8835 - val_loss: 0.3624 - val_bin_acc: 0.8560\n",
      "Epoch 10/50\n",
      "26/26 [==============================] - 24s 613ms/step - loss: 0.2811 - bin_acc: 0.8828 - val_loss: 0.4130 - val_bin_acc: 0.8521\n",
      "Epoch 11/50\n",
      "26/26 [==============================] - 23s 629ms/step - loss: 0.2804 - bin_acc: 0.8811 - val_loss: 0.5356 - val_bin_acc: 0.8154\n",
      "Epoch 12/50\n",
      "26/26 [==============================] - 23s 619ms/step - loss: 0.2718 - bin_acc: 0.8886 - val_loss: 0.4645 - val_bin_acc: 0.8483\n",
      "Epoch 13/50\n",
      "26/26 [==============================] - 23s 583ms/step - loss: 0.2529 - bin_acc: 0.8984 - val_loss: 0.3314 - val_bin_acc: 0.8705\n",
      "Epoch 14/50\n",
      "26/26 [==============================] - 24s 615ms/step - loss: 0.2572 - bin_acc: 0.8970 - val_loss: 0.3997 - val_bin_acc: 0.8662\n",
      "Epoch 15/50\n",
      "26/26 [==============================] - 22s 551ms/step - loss: 0.2444 - bin_acc: 0.8979 - val_loss: 0.4706 - val_bin_acc: 0.8124\n",
      "Epoch 16/50\n",
      "26/26 [==============================] - 21s 532ms/step - loss: 0.2162 - bin_acc: 0.9150 - val_loss: 0.4006 - val_bin_acc: 0.8688\n",
      "Epoch 17/50\n",
      "26/26 [==============================] - 21s 535ms/step - loss: 0.2223 - bin_acc: 0.9145 - val_loss: 0.6992 - val_bin_acc: 0.8248\n",
      "Epoch 18/50\n",
      "26/26 [==============================] - 22s 549ms/step - loss: 0.2371 - bin_acc: 0.9035 - val_loss: 0.4551 - val_bin_acc: 0.7932\n",
      "Epoch 19/50\n",
      "26/26 [==============================] - 24s 598ms/step - loss: 0.2004 - bin_acc: 0.9187 - val_loss: 0.4699 - val_bin_acc: 0.8188\n",
      "Epoch 20/50\n",
      "26/26 [==============================] - 23s 620ms/step - loss: 0.2134 - bin_acc: 0.9174 - val_loss: 0.9462 - val_bin_acc: 0.7675\n",
      "Epoch 21/50\n",
      "26/26 [==============================] - 22s 553ms/step - loss: 0.2089 - bin_acc: 0.9179 - val_loss: 0.5441 - val_bin_acc: 0.7902\n",
      "Epoch 22/50\n",
      "26/26 [==============================] - 20s 519ms/step - loss: 0.1844 - bin_acc: 0.9256 - val_loss: 1.0034 - val_bin_acc: 0.7299\n",
      "Epoch 23/50\n",
      "26/26 [==============================] - 21s 537ms/step - loss: 0.2105 - bin_acc: 0.9164 - val_loss: 11.3491 - val_bin_acc: 0.8235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16e0a0d5198>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model.fit(train_ds, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1, validation_data=test_ds, callbacks = myCallbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prec_recall_fscore(tp,fp,fn,tn):\n",
    "    \n",
    "    if tp+fp == 0:\n",
    "        prec = np.nan\n",
    "    else:\n",
    "        prec = np.round(tp/(tp+fp),3)\n",
    "        \n",
    "    if tp+fn == 0:\n",
    "        recall = np.nan\n",
    "    else:\n",
    "        recall = np.round(tp/(tp+fn),3)\n",
    "        \n",
    "    if prec + recall == 0:\n",
    "        fscore = np.nan\n",
    "    else:\n",
    "        fscore = np.round((2 * prec * recall)/(prec + recall),3)\n",
    "    \n",
    "    return prec, recall, fscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_prec_recall(res,gnd_truth, typeArr):\n",
    "    \n",
    "    \"\"\"Outputs accuracy, precision, recall, fscore for each class in a multi-label problem\n",
    "    \n",
    "    Inputs: \n",
    "        res : 2-D boolean numpy array containing the model predictions\n",
    "        gnd_truth: 2-D boolean numpy array containing ground truth\n",
    "        typeArr: 1-D numpy array of strings in which the column of the class label corresponds to the column in the ground truth array\n",
    "    \n",
    "    Outputs:\n",
    "        output: Python dictionary containing the accuracy, precision, recall, fscore for each class\n",
    "        overall_acc: float value of the overall accuracy in the whole dataset\n",
    "    \"\"\"\n",
    "        \n",
    "    output = dict()\n",
    "    overallOutput = dict()\n",
    "        \n",
    "    equal = res==gnd_truth\n",
    "    \n",
    "    # overall\n",
    "    tp = np.sum((res==1) & (gnd_truth==1),axis=None)\n",
    "    fp = np.sum((res==1) & (gnd_truth==0),axis=None)\n",
    "    fn = np.sum((res==0) & (gnd_truth==1),axis=None)\n",
    "    tn = np.sum((res==0) & (gnd_truth==0),axis=None)\n",
    "    overallOutput[\"acc\"] = np.round(np.sum(equal,axis=None)/np.multiply.reduce(equal.shape),3) # overall accuracy\n",
    "    overallOutput[\"prec\"], overallOutput[\"recall\"], overallOutput[\"fscore\"] = prec_recall_fscore(tp,fp,fn,tn)\n",
    "    \n",
    "    # per class\n",
    "    for i in range(equal.shape[1]):\n",
    "        output[typeArr[i]] = {\"count\": 0,\"acc\":0, \"prec\":0, \"recall\":0, \"fscore\" : 0}\n",
    "\n",
    "        output[typeArr[i]][\"count\"] = np.sum(gnd_truth[:,i]==1, axis=None)\n",
    "\n",
    "        tp = np.sum((res[:,i]==1) & (gnd_truth[:,i]==1),axis=None)\n",
    "        fp = np.sum((res[:,i]==1) & (gnd_truth[:,i]==0),axis=None)\n",
    "        fn = np.sum((res[:,i]==0) & (gnd_truth[:,i]==1),axis=None)\n",
    "        tn = np.sum((res[:,i]==0) & (gnd_truth[:,i]==0),axis=None)\n",
    "\n",
    "        output[typeArr[i]][\"acc\"] = np.round((tp+tn)/(tp+tn+fp+fn),3)\n",
    "        output[typeArr[i]][\"prec\"], output[typeArr[i]][\"recall\"], output[typeArr[i]][\"fscore\"] = prec_recall_fscore(tp,fp,fn,tn)\n",
    "        \n",
    "\n",
    "    return output, overallOutput\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImages = tf.data.Dataset.list_files(\"malaria/test/*.png\", shuffle=False)\n",
    "test_ds = testImages.map(process_path, num_parallel_calls=autoTune)\n",
    "test_ds = configure_for_performance(test_ds, shuffle=False)\n",
    "\n",
    "pred = model.predict(test_ds, batch_size=BATCH_SIZE)\n",
    "res = pred>=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgOrder = [f.numpy().decode('UTF-8') for f in testImages]\n",
    "\n",
    "gnd_truth = np.zeros(shape=(len(imgOrder),num_classes),dtype=\"bool\")\n",
    "\n",
    "i=0\n",
    "for file in imgOrder:\n",
    "    gnd_truth[i,:] = np.load(file.replace(\"test\",\"Y_nobb\").replace(\".png\",\".npy\"),allow_pickle=True, fix_imports=False)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "red blood cell {'count': 390, 'acc': 1.0, 'prec': 1.0, 'recall': 1.0, 'fscore': 1.0}\n",
      "leukocyte {'count': 33, 'acc': 0.897, 'prec': 0.37, 'recall': 0.303, 'fscore': 0.333}\n",
      "schizont {'count': 49, 'acc': 0.879, 'prec': 0.562, 'recall': 0.184, 'fscore': 0.277}\n",
      "gametocyte {'count': 45, 'acc': 0.885, 'prec': nan, 'recall': 0.0, 'fscore': nan}\n",
      "ring {'count': 78, 'acc': 0.813, 'prec': 0.558, 'recall': 0.308, 'fscore': 0.397}\n",
      "trophozoite {'count': 193, 'acc': 0.749, 'prec': 0.868, 'recall': 0.58, 'fscore': 0.695}\n"
     ]
    }
   ],
   "source": [
    "class_metrics, acc = acc_prec_recall(res,gnd_truth,typeArr)\n",
    "\n",
    "for k in class_metrics:\n",
    "    print(k, class_metrics[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': 0.871, 'prec': 0.901, 'recall': 0.692, 'fscore': 0.783}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
